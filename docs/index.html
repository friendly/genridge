<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Generalized Ridge Trace Plots for Ridge Regression â€¢ genridge</title>
<!-- favicons --><link rel="icon" type="image/png" sizes="16x16" href="favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="favicon-32x32.png">
<link rel="apple-touch-icon" type="image/png" sizes="180x180" href="apple-touch-icon.png">
<link rel="apple-touch-icon" type="image/png" sizes="120x120" href="apple-touch-icon-120x120.png">
<link rel="apple-touch-icon" type="image/png" sizes="76x76" href="apple-touch-icon-76x76.png">
<link rel="apple-touch-icon" type="image/png" sizes="60x60" href="apple-touch-icon-60x60.png">
<script src="deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet">
<script src="deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><link href="deps/Roboto-0.4.9/font.css" rel="stylesheet">
<link href="deps/JetBrains_Mono-0.4.9/font.css" rel="stylesheet">
<link href="deps/Roboto_Slab-0.4.9/font.css" rel="stylesheet">
<link href="deps/font-awesome-6.4.2/css/all.min.css" rel="stylesheet">
<link href="deps/font-awesome-6.4.2/css/v4-shims.min.css" rel="stylesheet">
<script src="deps/headroom-0.11.0/headroom.min.js"></script><script src="deps/headroom-0.11.0/jQuery.headroom.min.js"></script><script src="deps/bootstrap-toc-1.0.1/bootstrap-toc.min.js"></script><script src="deps/clipboard.js-2.0.11/clipboard.min.js"></script><script src="deps/search-1.0.0/autocomplete.jquery.min.js"></script><script src="deps/search-1.0.0/fuse.min.js"></script><script src="deps/search-1.0.0/mark.min.js"></script><!-- pkgdown --><script src="pkgdown.js"></script><meta property="og:title" content="Generalized Ridge Trace Plots for Ridge Regression">
<meta name="description" content="The genridge package introduces generalizations of the standard univariate ridge trace plot used in ridge regression and related methods. These graphical methods show both bias (actually, shrinkage) and precision, by plotting the covariance ellipsoids of the estimated coefficients, rather than just the estimates themselves. 2D and 3D plotting methods are provided, both in the space of the predictor variables and in the transformed space of the PCA/SVD of the predictors.">
<meta property="og:description" content="The genridge package introduces generalizations of the standard univariate ridge trace plot used in ridge regression and related methods. These graphical methods show both bias (actually, shrinkage) and precision, by plotting the covariance ellipsoids of the estimated coefficients, rather than just the estimates themselves. 2D and 3D plotting methods are provided, both in the space of the predictor variables and in the transformed space of the PCA/SVD of the predictors.">
<meta property="og:image" content="https://friendly.github.io/genridge/logo.png">
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>


    <nav class="navbar navbar-expand-lg fixed-top bg-light" data-bs-theme="light" aria-label="Site navigation"><div class="container">

    <a class="navbar-brand me-2" href="index.html">genridge</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">0.7.1</small>


    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="nav-item"><a class="nav-link" href="reference/index.html">Reference</a></li>
<li class="nav-item"><a class="nav-link" href="news/index.html">Changelog</a></li>
      </ul>
<ul class="navbar-nav">
<li class="nav-item"><form class="form-inline" role="search">
 <input class="form-control" type="search" name="search-input" id="search-input" autocomplete="off" aria-label="Search site" placeholder="Search for" data-search-index="search.json">
</form></li>
<li class="nav-item"><a class="external-link nav-link" href="https://github.com/friendly/genridge/" aria-label="GitHub"><span class="fa fab fa-github fa-lg"></span></a></li>
      </ul>
</div>


  </div>
</nav><div class="container template-home">
<div class="row">
  <main id="main" class="col-md-9">
<!-- badges: end -->
<div class="section level1">
<div class="page-header">
<img src="logo.png" class="logo" alt=""><h1 id="genridge-">genridge <a class="anchor" aria-label="anchor" href="#genridge-"></a>
</h1>
</div>
<div class="section level2">
<h2 id="generalized-ridge-trace-plots-for-ridge-regression">Generalized Ridge Trace Plots for Ridge Regression<a class="anchor" aria-label="anchor" href="#generalized-ridge-trace-plots-for-ridge-regression"></a>
</h2>
<p>Version 0.7.1</p>
<div class="section level3">
<h3 id="what-is-ridge-regression">What is ridge regression?<a class="anchor" aria-label="anchor" href="#what-is-ridge-regression"></a>
</h3>
<p>Consider the standard linear model, <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ğ²</mi><mo>=</mo><mi>ğ—</mi><mspace width="0.278em"></mspace><mi>ğ›ƒ</mi><mo>+</mo><mi>ğ›œ</mi></mrow><annotation encoding="application/x-tex">\mathbf{y} = \mathbf{X} \; \mathbf{\beta} + \mathbf{\epsilon}</annotation></semantics></math> for <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>p</mi><annotation encoding="application/x-tex">p</annotation></semantics></math> predictors in a multiple regression. In this context, high multiple correlations among the predictors lead to well-known problems of collinearity under ordinary least squares (OLS) estimation, which result in unstable estimates of the parameters in Î²: standard errors are inflated and estimated coefficients tend to be too large in absolute value on average.</p>
<p>Ridge regression is an instance of a class of techniques designed to obtain more favorable predictions at the expense of some increase in bias, compared to ordinary least squares (OLS) estimation. An essential idea behind these methods is that the OLS estimates are constrained in some way, shrinking them, on average, toward zero, to satisfy increased predictive accuracy.</p>
<p>The OLS estimates, which minimize the sum of squared residuals <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>R</mi><mi>S</mi><mi>S</mi><mo>=</mo><mi>Î£</mi><msup><mi>ğ›œ</mi><mn>2</mn></msup></mrow><annotation encoding="application/x-tex">RSS = \Sigma \mathbf{\epsilon}^2</annotation></semantics></math> are given by: <math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mover><mi>ğ›ƒ</mi><mo accent="true">Ì‚</mo></mover><mrow><mi mathvariant="normal">O</mi><mi mathvariant="normal">L</mi><mi mathvariant="normal">S</mi></mrow></msup><mo>=</mo><msup><mrow><mo stretchy="true" form="prefix">(</mo><msup><mi>ğ—</mi><mi>âŠ¤</mi></msup><mi>ğ—</mi><mo stretchy="true" form="postfix">)</mo></mrow><mrow><mi>âˆ’</mi><mn>1</mn></mrow></msup><msup><mi>ğ—</mi><mi>âŠ¤</mi></msup><mi>ğ²</mi><mspace width="0.278em"></mspace><mo>,</mo></mrow><annotation encoding="application/x-tex">
\widehat{\mathbf{\beta}}^{\mathrm{OLS}} = (\mathbf{X}^\top \mathbf{X})^{-1} \mathbf{X}^\top \mathbf{y} \; ,
</annotation></semantics></math> with <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover><mtext mathvariant="normal">Var</mtext><mo accent="true">Ì‚</mo></mover><mrow><mo stretchy="true" form="prefix">(</mo><msup><mover><mi>ğ›ƒ</mi><mo accent="true">Ì‚</mo></mover><mrow><mi mathvariant="normal">O</mi><mi mathvariant="normal">L</mi><mi mathvariant="normal">S</mi></mrow></msup><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><msup><mover><mi>Ïƒ</mi><mo accent="true">Ì‚</mo></mover><mn>2</mn></msup><msup><mrow><mo stretchy="true" form="prefix">(</mo><msup><mi>ğ—</mi><mi>âŠ¤</mi></msup><mi>ğ—</mi><mo stretchy="true" form="postfix">)</mo></mrow><mrow><mi>âˆ’</mi><mn>1</mn></mrow></msup></mrow><annotation encoding="application/x-tex">\widehat{\text{Var}} (\widehat{\mathbf{\beta}}^{\mathrm{OLS}}) = \widehat{\sigma}^2 (\mathbf{X}^\top \mathbf{X})^{-1}</annotation></semantics></math>.</p>
<p>Ridge regression replaces the standard residual sum of squares criterion with a penalized form,</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mrow><mi mathvariant="normal">R</mi><mi mathvariant="normal">S</mi><mi mathvariant="normal">S</mi></mrow><mrow><mo stretchy="true" form="prefix">(</mo><mi>Î»</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><msup><mrow><mo stretchy="true" form="prefix">(</mo><mi>ğ²</mi><mo>âˆ’</mo><mi>ğ—</mi><mi>ğ›ƒ</mi><mo stretchy="true" form="postfix">)</mo></mrow><mi>âŠ¤</mi></msup><mrow><mo stretchy="true" form="prefix">(</mo><mi>ğ²</mi><mo>âˆ’</mo><mi>ğ—</mi><mi>ğ›ƒ</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>+</mo><mi>Î»</mi><msup><mi>ğ›ƒ</mi><mi>âŠ¤</mi></msup><mi>ğ›ƒ</mi><mspace width="1.0em"></mspace><mspace width="1.0em"></mspace><mrow><mo stretchy="true" form="prefix">(</mo><mi>Î»</mi><mo>â‰¥</mo><mn>0</mn><mo stretchy="true" form="postfix">)</mo></mrow><mspace width="0.222em"></mspace><mo>,</mo></mrow><annotation encoding="application/x-tex">
\mathrm{RSS}(\lambda) = (\mathbf{y}-\mathbf{X} \mathbf{\beta})^\top  (\mathbf{y}-\mathbf{X} \mathbf{\beta}) + \lambda \mathbf{\beta}^\top \mathbf{\beta} \quad\quad (\lambda \ge 0) \: ,
</annotation></semantics></math></p>
<p>whose solution is easily seen to be:</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mover><mi>ğ›ƒ</mi><mo accent="true">Ì‚</mo></mover><mi>k</mi><mrow><mi mathvariant="normal">R</mi><mi mathvariant="normal">R</mi></mrow></msubsup><mo>=</mo><msup><mrow><mo stretchy="true" form="prefix">(</mo><msup><mi>ğ—</mi><mi>âŠ¤</mi></msup><mi>ğ—</mi><mo>+</mo><mi>Î»</mi><mi>ğˆ</mi><mo stretchy="true" form="postfix">)</mo></mrow><mrow><mi>âˆ’</mi><mn>1</mn></mrow></msup><msup><mi>ğ—</mi><mi>âŠ¤</mi></msup><mi>ğ²</mi></mrow><annotation encoding="application/x-tex">
\widehat{\mathbf{\beta}}^{\mathrm{RR}}_k  = (\mathbf{X}^\top \mathbf{X} + \lambda \mathbf{I})^{-1} \mathbf{X}^\top \mathbf{y}
</annotation></semantics></math></p>
<p>where <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Î»</mi><annotation encoding="application/x-tex">\lambda</annotation></semantics></math> is the <em>shrinkage factor</em> or <em>tuning constant</em>, penalizing larger coefficients. Shrinkage can also be expressed as the equivalent degrees of freedom, the trace of the analog of the â€œhatâ€ matrix, <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext mathvariant="normal">tr</mtext><mrow><mo stretchy="true" form="prefix">[</mo><msup><mrow><mo stretchy="true" form="prefix">(</mo><msup><mi>ğ—</mi><mi>âŠ¤</mi></msup><mi>ğ—</mi><mo>+</mo><mi>Î»</mi><mi>ğˆ</mi><mo stretchy="true" form="postfix">)</mo></mrow><mrow><mi>âˆ’</mi><mn>1</mn></mrow></msup><msup><mi>ğ—</mi><mi>âŠ¤</mi></msup><mo stretchy="true" form="postfix">]</mo></mrow></mrow><annotation encoding="application/x-tex">\text{tr}[(\mathbf{X}^\top \mathbf{X} + \lambda \mathbf{I})^{-1} \mathbf{X}^\top]</annotation></semantics></math>. In general,</p>
<ul>
<li>The bias increases as Î» increases,</li>
<li>The sampling variance decreases as Î» increases.</li>
</ul>
<p>One goal of the <code>genridge</code> package is to provide visualization methods for these models to help understand the tradeoff between bias and variance and choice of a shrinkage value <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Î»</mi><annotation encoding="application/x-tex">\lambda</annotation></semantics></math>.</p>
</div>
<div class="section level3">
<h3 id="package-overview">Package overview<a class="anchor" aria-label="anchor" href="#package-overview"></a>
</h3>
<p>The <code>genridge</code> package introduces generalizations of the standard univariate ridge trace plot used in ridge regression and related methods (Friendly, 2011, 2013). These graphical methods show both bias (actually, shrinkage) and precision, by plotting the covariance ellipsoids of the estimated coefficients, rather than just the estimates themselves. 2D and 3D plotting methods are provided, both in the space of the predictor variables and in the transformed space of the PCA/SVD of the predictors.</p>
</div>
<div class="section level3">
<h3 id="details">Details<a class="anchor" aria-label="anchor" href="#details"></a>
</h3>
<p>This package provides computational support for the graphical methods described in Friendly (2013). Ridge regression models may be fit using the function <code>ridge</code>, which incorporates features of <code><a href="https://rdrr.io/pkg/MASS/man/lm.ridge.html" class="external-link">MASS::lm.ridge()</a></code> and <code>ElemStatLearn::simple.ridge()</code>. In particular, the shrinkage factors in ridge regression may be specified either in terms of the constant (<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Î»</mi><annotation encoding="application/x-tex">\lambda</annotation></semantics></math>) added to the diagonal of <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>X</mi><mi>âŠ¤</mi></msup><mi>X</mi></mrow><annotation encoding="application/x-tex">X^\top X</annotation></semantics></math> matrix, or the equivalent number of degrees of freedom.</p>
<p>The following computational functions are provided:</p>
<ul>
<li>
<code><a href="reference/ridge.html">ridge()</a></code> Calculates ridge regregression estimates; returns an object of class <code>"ridge"</code>
</li>
<li>
<code><a href="reference/pca.html">pca.ridge()</a></code> Transform coefcients and covariance matrices to PCA/SVD space; returns an object of class <code>c("pcaridge", "ridge")</code>
</li>
<li>
<code><a href="reference/vif.ridge.html">vif.ridge()</a></code> Calculates VIFs for â€œridgeâ€ objects</li>
<li>
<code><a href="reference/precision.html">precision()</a></code> Calculates measures of precision and shrinkage</li>
</ul>
<p>More importantly, the <code>ridge</code> functions also calculate and returns the associated covariance matrices of each of the ridge estimates, allowing precision to be studied and displayed graphically.</p>
<p>This provides the support for the main plotting functions in the package:</p>
<ul>
<li>
<code><a href="reference/traceplot.html">traceplot()</a></code>: Traditional univariate ridge trace plots</li>
<li>
<code><a href="reference/plot.ridge.html">plot.ridge()</a></code>: Bivariate ridge trace plots, showing the covariance ellipse of the estimated coefficients.</li>
<li>
<code><a href="reference/pairs.ridge.html">pairs.ridge()</a></code>: All pairwise bivariate ridge trace plots</li>
<li>
<code><a href="reference/plot3d.html">plot3d.ridge()</a></code>: 3D ridge trace plots with ellipsoids</li>
</ul>
<p>In addition, the <code><a href="reference/pca.html">pca()</a></code> method for <code>"ridge"</code> objects transforms the coefficients and covariance matrices of a ridge object from predictor space to the equivalent, but more interesting space of the PCA of <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>X</mi><mi>âŠ¤</mi></msup><mi>X</mi></mrow><annotation encoding="application/x-tex">X^\top X</annotation></semantics></math> or the SVD of <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>X</mi><annotation encoding="application/x-tex">X</annotation></semantics></math>. The main plotting functions also work for these objects, of class <code>c("ridge", "pcaridge")</code>.</p>
<ul>
<li>
<code><a href="reference/biplot.pcaridge.html">biplot.pcaridge()</a></code>: Adds variable vectors to the bivariate plots of coefficients in PCA space</li>
</ul>
<p>Finally, the functions <code><a href="reference/precision.html">precision()</a></code> and <code><a href="reference/vif.ridge.html">vif.ridge()</a></code> provide other useful measures and plots.</p>
</div>
</div>
<div class="section level2">
<h2 id="installation">Installation<a class="anchor" aria-label="anchor" href="#installation"></a>
</h2>
<table class="table">
<colgroup>
<col width="50%">
<col width="50%">
</colgroup>
<tbody>
<tr class="odd">
<td>CRAN version</td>
<td><code>install.packages("genridge")</code></td>
</tr>
<tr class="even">
<td>R-universe</td>
<td><code>install.packages("genridge", repos = c('https://friendly.r-universe.dev')</code></td>
</tr>
<tr class="odd">
<td>Development version</td>
<td><code>remotes::install_github("friendly/genridge")</code></td>
</tr>
</tbody>
</table>
</div>
<div class="section level2">
<h2 id="examples">Examples<a class="anchor" aria-label="anchor" href="#examples"></a>
</h2>
<p>The classic example for ridge regression is Longleyâ€™s (1967) data, consisting of 7 economic variables, observed yearly from 1947 to 1962 (n=16), in the data frame <code><a href="https://rdrr.io/r/datasets/longley.html" class="external-link">datasets::longley</a></code>. The goal is to predict <code>Employed</code> from <code>GNP</code>, <code>Unemployed</code>, <code>Armed.Forces</code>, <code>Population</code>, <code>Year</code>, <code>GNP.deflator</code>.</p>
<p>These data, constructed to illustrate numerical problems in least squares software at the time, are (purposely) perverse, in that:</p>
<ul>
<li>each variable is a time series so that there is clearly a lack of independence among predictors.</li>
<li>worse, there is also some <em>structural collinearity</em> among the variables <code>GNP</code>, <code>Year</code>, <code>GNP.deflator</code>, <code>Population</code>, e.g., <code>GNP.deflator</code> is a multiplicative factor to account for inflation.</li>
</ul>
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/utils/data.html" class="external-link">data</a></span><span class="op">(</span><span class="va">longley</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/str.html" class="external-link">str</a></span><span class="op">(</span><span class="va">longley</span><span class="op">)</span></span>
<span><span class="co">#&gt; 'data.frame':    16 obs. of  7 variables:</span></span>
<span><span class="co">#&gt;  $ GNP.deflator: num  83 88.5 88.2 89.5 96.2 ...</span></span>
<span><span class="co">#&gt;  $ GNP         : num  234 259 258 285 329 ...</span></span>
<span><span class="co">#&gt;  $ Unemployed  : num  236 232 368 335 210 ...</span></span>
<span><span class="co">#&gt;  $ Armed.Forces: num  159 146 162 165 310 ...</span></span>
<span><span class="co">#&gt;  $ Population  : num  108 109 110 111 112 ...</span></span>
<span><span class="co">#&gt;  $ Year        : int  1947 1948 1949 1950 1951 1952 1953 1954 1955 1956 ...</span></span>
<span><span class="co">#&gt;  $ Employed    : num  60.3 61.1 60.2 61.2 63.2 ...</span></span></code></pre></div>
<p>Shrinkage values, can be specified using either <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Î»</mi><annotation encoding="application/x-tex">\lambda</annotation></semantics></math> (where <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Î»</mi><mo>=</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">\lambda = 0</annotation></semantics></math> corresponds to OLS), or equivalent effective degrees of freedom. This quantifies the tradeoff between bias and variance for predictive modeling, where OLS has low bias, but can have large predictive variance.</p>
<p><code><a href="reference/ridge.html">ridge()</a></code> returns a matrix containing the coefficients for each predictor for each shrinkage value and other quantities.</p>
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">lambda</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">0.005</span>, <span class="fl">0.01</span>, <span class="fl">0.02</span>, <span class="fl">0.04</span>, <span class="fl">0.08</span><span class="op">)</span></span>
<span><span class="va">lridge</span> <span class="op">&lt;-</span> <span class="fu"><a href="reference/ridge.html">ridge</a></span><span class="op">(</span><span class="va">Employed</span> <span class="op">~</span> <span class="va">GNP</span> <span class="op">+</span> <span class="va">Unemployed</span> <span class="op">+</span> <span class="va">Armed.Forces</span> <span class="op">+</span> <span class="va">Population</span> <span class="op">+</span> <span class="va">Year</span> <span class="op">+</span> <span class="va">GNP.deflator</span>, </span>
<span>        data<span class="op">=</span><span class="va">longley</span>, lambda<span class="op">=</span><span class="va">lambda</span><span class="op">)</span></span>
<span><span class="va">lridge</span></span>
<span><span class="co">#&gt; Ridge Coefficients:</span></span>
<span><span class="co">#&gt;        GNP        Unemployed  Armed.Forces  Population  Year       GNP.deflator</span></span>
<span><span class="co">#&gt; 0.000  -3.447192  -1.827886   -0.696210     -0.344197    8.431972   0.157380   </span></span>
<span><span class="co">#&gt; 0.005  -1.042478  -1.491395   -0.623468     -0.935580    6.566532  -0.041750   </span></span>
<span><span class="co">#&gt; 0.010  -0.179797  -1.361047   -0.588140     -1.003168    5.656287  -0.026122   </span></span>
<span><span class="co">#&gt; 0.020   0.499494  -1.245137   -0.547633     -0.867553    4.626116   0.097663   </span></span>
<span><span class="co">#&gt; 0.040   0.905947  -1.155229   -0.503911     -0.523471    3.576502   0.321240   </span></span>
<span><span class="co">#&gt; 0.080   1.090705  -1.086421   -0.458252     -0.085963    2.641649   0.570252</span></span></code></pre></div>
<div class="section level3">
<h3 id="variance-inflation-factors">Variance Inflation Factors<a class="anchor" aria-label="anchor" href="#variance-inflation-factors"></a>
</h3>
<p>The effects of collinearity can be measured by a variance inflation factor (VIF), the ratio of the sampling variances of the coefficients, relative to what they would be if all predictors were uncorrelated, given by <math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext mathvariant="normal">VIF</mtext><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>Î²</mi><mi>i</mi></msub><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><mfrac><mn>1</mn><mrow><mn>1</mn><mo>âˆ’</mo><msubsup><mi>R</mi><mrow><mi>i</mi><mo stretchy="false" form="prefix">|</mo><mtext mathvariant="normal">others</mtext></mrow><mn>2</mn></msubsup></mrow></mfrac><mspace width="0.278em"></mspace><mo>,</mo></mrow><annotation encoding="application/x-tex">
\text{VIF}(\beta_i) = \frac{1}{1 - R^2_{i | \text{others}}} \; ,
</annotation></semantics></math> where â€œothersâ€ represents all other predictors except <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>X</mi><mi>i</mi></msub><annotation encoding="application/x-tex">X_i</annotation></semantics></math>.</p>
<p><code>vif()</code> for a <code>"ridge"</code> object calculates variance inflation factors for all values of the ridge constant. You can see that for OLS, nearly all VIF values are dangerously high. With a ridge factor of 0.04 or greater, variance inflation has been considerably reduced for a few of the predictors.</p>
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu">vif</span><span class="op">(</span><span class="va">lridge</span><span class="op">)</span></span>
<span><span class="co">#&gt;           GNP Unemployed Armed.Forces Population   Year GNP.deflator</span></span>
<span><span class="co">#&gt; 0.000 1788.51     33.619        3.589     399.15 758.98       135.53</span></span>
<span><span class="co">#&gt; 0.005  540.04     12.118        2.921     193.30 336.15        90.63</span></span>
<span><span class="co">#&gt; 0.010  259.00      7.284        2.733     134.42 218.84        74.79</span></span>
<span><span class="co">#&gt; 0.020  101.12      4.573        2.578      87.29 128.82        58.94</span></span>
<span><span class="co">#&gt; 0.040   34.43      3.422        2.441      52.22  66.31        43.56</span></span>
<span><span class="co">#&gt; 0.080   11.28      2.994        2.301      28.59  28.82        29.52</span></span></code></pre></div>
</div>
<div class="section level3">
<h3 id="univariate-trace-plots">Univariate trace plots<a class="anchor" aria-label="anchor" href="#univariate-trace-plots"></a>
</h3>
<p>A standard, univariate, <code><a href="reference/traceplot.html">traceplot()</a></code> simply plots the estimated coefficients for each predictor against the shrinkage factor, <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Î»</mi><annotation encoding="application/x-tex">\lambda</annotation></semantics></math>.</p>
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="reference/traceplot.html">traceplot</a></span><span class="op">(</span><span class="va">lridge</span>, xlim <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="op">-</span><span class="fl">0.02</span>, <span class="fl">0.08</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<figure><img src="reference/figures/README-longley-tp1-1.png" alt="Univariate ridge trace plot for the coefficients of predictors of Employment in Longleyâ€™s data via ridge regression, with ridge constants k = 0, 0.005, 0.01, 0.02, 0.04, 0.08."><figcaption aria-hidden="true">
Univariate ridge trace plot for the coefficients of predictors of Employment in Longleyâ€™s data via ridge regression, with ridge constants k = 0, 0.005, 0.01, 0.02, 0.04, 0.08.
</figcaption></figure><p>The dotted lines show choices for the ridge constant by two commonly used criteria to balance bias against precision due to <strong>HKB</strong>: Hoerl, Kennard, and Baldwin (1975) and <strong>LW</strong>: Lawless and Wang (1976). These values (along with a generalized cross-validation value GCV) are also stored in the <code>"ridge"</code> object,</p>
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span>HKB<span class="op">=</span><span class="va">lridge</span><span class="op">$</span><span class="va">kHKB</span>, LW<span class="op">=</span><span class="va">lridge</span><span class="op">$</span><span class="va">kLW</span>, GCV<span class="op">=</span><span class="va">lridge</span><span class="op">$</span><span class="va">kGCV</span><span class="op">)</span></span>
<span><span class="co">#&gt;      HKB       LW      GCV </span></span>
<span><span class="co">#&gt; 0.004275 0.032295 0.005000</span></span></code></pre></div>
<p>These values seem rather small, but note that the coefficients for <code>Year</code> and <code>GNP</code> are shrunk considerably.</p>
</div>
<div class="section level3">
<h3 id="alternative-plot">Alternative plot<a class="anchor" aria-label="anchor" href="#alternative-plot"></a>
</h3>
<p>It is sometimes easier to interpret the plot when coefficients are plotted against the equivalent degrees of freedom, where <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Î»</mi><mo>=</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">\lambda = 0</annotation></semantics></math> corresponds to 6 degrees of freedom in the parameter space of six predictors.</p>
<div class="sourceCode" id="cb6"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="reference/traceplot.html">traceplot</a></span><span class="op">(</span><span class="va">lridge</span>, X<span class="op">=</span><span class="st">"df"</span>, xlim <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">4</span>, <span class="fl">6.5</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<figure><img src="reference/figures/README-longley-tp2-1.png" alt="Univariate ridge trace plot of coefficients against effective degrees of freedom."><figcaption aria-hidden="true">
Univariate ridge trace plot of coefficients against effective degrees of freedom.
</figcaption></figure><p><strong>But wait: This is the wrong plot!</strong> These plots show the trends in increased bias associated with larger <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Î»</mi><annotation encoding="application/x-tex">\lambda</annotation></semantics></math>, but they do <strong>not</strong> show the accompanying decrease in variance (increase in precision). For that, we need to consider the variances and covariances of the estimated coefficients. The univariate trace plot is the wrong graphic form for what is essentially a <em>multivariate</em> problem, where we would like to visualize how both coefficients and their variances change with <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Î»</mi><annotation encoding="application/x-tex">\lambda</annotation></semantics></math>.</p>
</div>
<div class="section level3">
<h3 id="bivariate-trace-plots">Bivariate trace plots<a class="anchor" aria-label="anchor" href="#bivariate-trace-plots"></a>
</h3>
<p>The bivariate analog of the trace plot suggested by Friendly (2013) plots bivariate confidence ellipses for pairs of coefficients. Their centers, <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="true" form="prefix">(</mo><msub><mover><mi>Î²</mi><mo accent="true">Ì‚</mo></mover><mi>i</mi></msub><mo>,</mo><msub><mover><mi>Î²</mi><mo accent="true">Ì‚</mo></mover><mi>j</mi></msub><mo stretchy="true" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">(\widehat{\beta}_i, \widehat{\beta}_j)</annotation></semantics></math> show the estimated coefficients, and their size and shape indicate sampling variance, <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover><mtext mathvariant="normal">Var</mtext><mo accent="true">Ì‚</mo></mover><mrow><mo stretchy="true" form="prefix">(</mo><msub><mover><mi>ğ›ƒ</mi><mo accent="true">Ì‚</mo></mover><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">\widehat{\text{Var}} (\mathbf{\widehat{\beta}}_{ij})</annotation></semantics></math>. Here, we plot those for <code>GNP</code> against four of the other predictors.</p>
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">op</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/graphics/par.html" class="external-link">par</a></span><span class="op">(</span>mfrow<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">2</span>,<span class="fl">2</span><span class="op">)</span>, mar<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">4</span>, <span class="fl">4</span>, <span class="fl">1</span>, <span class="fl">1</span><span class="op">)</span><span class="op">+</span> <span class="fl">0.1</span><span class="op">)</span></span>
<span><span class="va">clr</span> <span class="op">&lt;-</span>  <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"black"</span>, <span class="st">"red"</span>, <span class="st">"darkgreen"</span>,<span class="st">"blue"</span>, <span class="st">"cyan4"</span>, <span class="st">"magenta"</span><span class="op">)</span></span>
<span><span class="va">pch</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">15</span><span class="op">:</span><span class="fl">18</span>, <span class="fl">7</span>, <span class="fl">9</span><span class="op">)</span></span>
<span><span class="va">lambdaf</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/expression.html" class="external-link">expression</a></span><span class="op">(</span><span class="op">~</span><span class="fu">widehat</span><span class="op">(</span><span class="va">beta</span><span class="op">)</span><span class="op">^</span><span class="va">OLS</span><span class="op">)</span>, <span class="st">".005"</span>, <span class="st">".01"</span>, <span class="st">".02"</span>, <span class="st">".04"</span>, <span class="st">".08"</span><span class="op">)</span></span>
<span></span>
<span><span class="kw">for</span> <span class="op">(</span><span class="va">i</span> <span class="kw">in</span> <span class="fl">2</span><span class="op">:</span><span class="fl">5</span><span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">lridge</span>, variables<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">1</span>,<span class="va">i</span><span class="op">)</span>, </span>
<span>         radius<span class="op">=</span><span class="fl">0.5</span>, cex.lab<span class="op">=</span><span class="fl">1.5</span>, col<span class="op">=</span><span class="va">clr</span>, </span>
<span>         labels<span class="op">=</span><span class="cn">NULL</span>, fill<span class="op">=</span><span class="cn">TRUE</span>, fill.alpha<span class="op">=</span><span class="fl">0.2</span><span class="op">)</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/graphics/text.html" class="external-link">text</a></span><span class="op">(</span><span class="va">lridge</span><span class="op">$</span><span class="va">coef</span><span class="op">[</span><span class="fl">1</span>,<span class="fl">1</span><span class="op">]</span>, <span class="va">lridge</span><span class="op">$</span><span class="va">coef</span><span class="op">[</span><span class="fl">1</span>,<span class="va">i</span><span class="op">]</span>, </span>
<span>         <span class="fu"><a href="https://rdrr.io/r/base/expression.html" class="external-link">expression</a></span><span class="op">(</span><span class="op">~</span><span class="fu">widehat</span><span class="op">(</span><span class="va">beta</span><span class="op">)</span><span class="op">^</span><span class="va">OLS</span><span class="op">)</span>, cex<span class="op">=</span><span class="fl">1.5</span>, pos<span class="op">=</span><span class="fl">4</span>, offset<span class="op">=</span><span class="fl">.1</span><span class="op">)</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/graphics/text.html" class="external-link">text</a></span><span class="op">(</span><span class="va">lridge</span><span class="op">$</span><span class="va">coef</span><span class="op">[</span><span class="op">-</span><span class="fl">1</span>,<span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">1</span>,<span class="va">i</span><span class="op">)</span><span class="op">]</span>, <span class="va">lambdaf</span><span class="op">[</span><span class="op">-</span><span class="fl">1</span><span class="op">]</span>, pos<span class="op">=</span><span class="fl">3</span>, cex<span class="op">=</span><span class="fl">1.3</span><span class="op">)</span></span>
<span><span class="op">}</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/par.html" class="external-link">par</a></span><span class="op">(</span><span class="va">op</span><span class="op">)</span></span></code></pre></div>
<div class="figure">
<img src="reference/figures/README-longley-plot-ridge-1.png" alt="Bivariate ridge trace plots for the coefficients of four predictors against the coefficient for GNP in Longleyâ€™s data, with Î» = 0, 0.005, 0.01, 0.02, 0.04, 0.08. In most cases, the coefficients are driven toward zero, but the bivariate plot also makes clear the reduction in variance, as well as the bivariate path of shrinkage." width="100%"><p class="caption">
Bivariate ridge trace plots for the coefficients of four predictors against the coefficient for GNP in Longleyâ€™s data, with Î» = 0, 0.005, 0.01, 0.02, 0.04, 0.08. In most cases, the coefficients are driven toward zero, but the bivariate plot also makes clear the reduction in variance, as well as the bivariate path of shrinkage.
</p>
</div>
<p>As can be seen, the coefficients for each pair of predictors trace a path generally in toward the origin <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="true" form="prefix">(</mo><mn>0</mn><mo>,</mo><mn>0</mn><mo stretchy="true" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">(0, 0)</annotation></semantics></math>, and the covariance ellipses get smaller, indicating increased precision.</p>
<p>The <code><a href="https://rdrr.io/r/graphics/pairs.html" class="external-link">pairs()</a></code> method for <code>"ridge"</code> objects shows all pairwise views in scatterplot matrix form.</p>
<div class="sourceCode" id="cb8"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/pairs.html" class="external-link">pairs</a></span><span class="op">(</span><span class="va">lridge</span>, radius<span class="op">=</span><span class="fl">0.5</span>, diag.cex <span class="op">=</span> <span class="fl">2</span>, </span>
<span>      fill <span class="op">=</span> <span class="cn">TRUE</span>, fill.alpha <span class="op">=</span> <span class="fl">0.1</span><span class="op">)</span></span></code></pre></div>
<div class="figure">
<img src="reference/figures/README-longley-pairs-1.png" alt="Scatterplot matrix of bivariate ridge trace plots" width="100%"><p class="caption">
Scatterplot matrix of bivariate ridge trace plots
</p>
</div>
<p>See Friendly et-al.Â (2013) for other examples of how elliptical thinking can lead to insights in statistical problems.</p>
</div>
<div class="section level3">
<h3 id="visualizing-the-bias-variance-tradeoff">Visualizing the bias-variance tradeoff<a class="anchor" aria-label="anchor" href="#visualizing-the-bias-variance-tradeoff"></a>
</h3>
<p>The function <code><a href="reference/precision.html">precision()</a></code> calculates a number of measures of the effect of shrinkage of the coefficients on the estimated sampling variance. Larger shrinkage <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Î»</mi><annotation encoding="application/x-tex">\lambda</annotation></semantics></math> should lead to smaller <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover><mtext mathvariant="normal">Var</mtext><mo accent="true">Ì‚</mo></mover><mrow><mo stretchy="true" form="prefix">(</mo><mover><mi>ğ›ƒ</mi><mo accent="true">Ì‚</mo></mover><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">\widehat{\text{Var}} (\mathbf{\widehat{\beta}})</annotation></semantics></math>, indicating increased precision. See: <code><a href="reference/precision.html">help(precision)</a></code> for details.</p>
<div class="sourceCode" id="cb9"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="reference/precision.html">precision</a></span><span class="op">(</span><span class="va">lridge</span><span class="op">)</span></span>
<span><span class="co">#&gt;       lambda    df    det   trace max.eig norm.beta</span></span>
<span><span class="co">#&gt; 0.000  0.000 6.000 -12.93 18.1190 15.4191    1.0000</span></span>
<span><span class="co">#&gt; 0.005  0.005 5.415 -14.41  6.8209  4.6065    0.7406</span></span>
<span><span class="co">#&gt; 0.010  0.010 5.135 -15.41  4.0423  2.1807    0.6365</span></span>
<span><span class="co">#&gt; 0.020  0.020 4.818 -16.83  2.2180  1.0255    0.5282</span></span>
<span><span class="co">#&gt; 0.040  0.040 4.478 -18.70  1.1647  0.5808    0.4233</span></span>
<span><span class="co">#&gt; 0.080  0.080 4.128 -21.05  0.5873  0.2599    0.3373</span></span></code></pre></div>
<p><code>norm.beta</code> <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>=</mo><mrow><mo stretchy="true" form="prefix">|</mo><mo stretchy="true" form="postfix">|</mo></mrow><mi>ğ›ƒ</mi><mrow><mo stretchy="true" form="prefix">|</mo><mo stretchy="true" form="postfix">|</mo></mrow><mi>/</mi><mo>max</mo><mrow><mrow><mo stretchy="true" form="prefix">|</mo><mo stretchy="true" form="postfix">|</mo></mrow><mi>ğ›ƒ</mi><mrow><mo stretchy="true" form="prefix">|</mo><mo stretchy="true" form="postfix">|</mo></mrow></mrow></mrow><annotation encoding="application/x-tex">= ||\mathbf{\beta}|| / \max{||\mathbf{\beta}||}</annotation></semantics></math> is a measure of shrinkage, and <code>det</code> <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>=</mo><mo>log</mo><mrow><mo stretchy="true" form="prefix">|</mo><mtext mathvariant="normal">Var</mtext><mrow><mo stretchy="true" form="prefix">(</mo><mi>ğ›ƒ</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo stretchy="true" form="postfix">|</mo></mrow></mrow><annotation encoding="application/x-tex">= \log{| \text{Var}(\mathbf{\beta}) |}</annotation></semantics></math>, is a measure of variance of the coefficients (inverse of precision). Plotting these against each other gives a direct view of the tradeoff between bias and precision.</p>
<div class="sourceCode" id="cb10"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">pdat</span> <span class="op">&lt;-</span> <span class="fu"><a href="reference/precision.html">precision</a></span><span class="op">(</span><span class="va">lridge</span><span class="op">)</span></span>
<span><span class="va">op</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/graphics/par.html" class="external-link">par</a></span><span class="op">(</span>mar<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">4</span>, <span class="fl">4</span>, <span class="fl">1</span>, <span class="fl">1</span><span class="op">)</span> <span class="op">+</span> <span class="fl">0.2</span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va">splines</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/with.html" class="external-link">with</a></span><span class="op">(</span><span class="va">pdat</span>, <span class="op">{</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">norm.beta</span>, <span class="va">det</span>, type<span class="op">=</span><span class="st">"b"</span>, </span>
<span>    cex.lab<span class="op">=</span><span class="fl">1.25</span>, pch<span class="op">=</span><span class="fl">16</span>, cex<span class="op">=</span><span class="fl">1.5</span>, col<span class="op">=</span><span class="va">clr</span>, lwd<span class="op">=</span><span class="fl">2</span>,</span>
<span>  xlab<span class="op">=</span><span class="st">'shrinkage: ||b|| / max(||b||)'</span>,</span>
<span>    ylab<span class="op">=</span><span class="st">'variance: log |Var(b)|'</span><span class="op">)</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/graphics/text.html" class="external-link">text</a></span><span class="op">(</span><span class="va">norm.beta</span>, <span class="va">det</span>, <span class="va">lambdaf</span>, cex<span class="op">=</span><span class="fl">1.25</span>, pos<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">2</span>,<span class="fu"><a href="https://rdrr.io/r/base/length.html" class="external-link">length</a></span><span class="op">(</span><span class="va">lambda</span><span class="op">)</span><span class="op">-</span><span class="fl">1</span><span class="op">)</span>,<span class="fl">4</span><span class="op">)</span>, xpd <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/graphics/text.html" class="external-link">text</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/Extremes.html" class="external-link">min</a></span><span class="op">(</span><span class="va">norm.beta</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/base/Extremes.html" class="external-link">max</a></span><span class="op">(</span><span class="va">det</span><span class="op">)</span>, <span class="st">"log |Variance| vs. Shrinkage"</span>, cex<span class="op">=</span><span class="fl">1.5</span>, pos<span class="op">=</span><span class="fl">4</span><span class="op">)</span></span>
<span>    <span class="op">}</span><span class="op">)</span></span>
<span><span class="va">mod</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html" class="external-link">lm</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/cbind.html" class="external-link">cbind</a></span><span class="op">(</span><span class="va">det</span>, <span class="va">norm.beta</span><span class="op">)</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/splines/bs.html" class="external-link">bs</a></span><span class="op">(</span><span class="va">lambda</span>, df<span class="op">=</span><span class="fl">5</span><span class="op">)</span>, data<span class="op">=</span><span class="va">pdat</span><span class="op">)</span></span>
<span><span class="va">x</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html" class="external-link">data.frame</a></span><span class="op">(</span>lambda<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="va">lridge</span><span class="op">$</span><span class="va">kHKB</span>, <span class="va">lridge</span><span class="op">$</span><span class="va">kLW</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">fit</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span><span class="va">mod</span>, <span class="va">x</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/points.html" class="external-link">points</a></span><span class="op">(</span><span class="va">fit</span><span class="op">[</span>,<span class="fl">2</span><span class="op">:</span><span class="fl">1</span><span class="op">]</span>, pch<span class="op">=</span><span class="fl">15</span>, col<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/grDevices/gray.html" class="external-link">gray</a></span><span class="op">(</span><span class="fl">.50</span><span class="op">)</span>, cex<span class="op">=</span><span class="fl">1.5</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/text.html" class="external-link">text</a></span><span class="op">(</span><span class="va">fit</span><span class="op">[</span>,<span class="fl">2</span><span class="op">:</span><span class="fl">1</span><span class="op">]</span>, <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"HKB"</span>, <span class="st">"LW"</span><span class="op">)</span>, pos<span class="op">=</span><span class="fl">3</span>, cex<span class="op">=</span><span class="fl">1.5</span>, col<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/grDevices/gray.html" class="external-link">gray</a></span><span class="op">(</span><span class="fl">.50</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/par.html" class="external-link">par</a></span><span class="op">(</span><span class="va">op</span><span class="op">)</span></span></code></pre></div>
<figure><img src="reference/figures/README-precision-plot-1.png" alt="Plot of log(Variance) vs.Â shrinkage to show the tradeoff between bias and variance."><figcaption aria-hidden="true">
Plot of log(Variance) vs.Â shrinkage to show the tradeoff between bias and variance.
</figcaption></figure>
</div>
</div>
<div class="section level2">
<h2 id="low-rank-views">Low-rank views<a class="anchor" aria-label="anchor" href="#low-rank-views"></a>
</h2>
<p>Just as principal components analysis gives low-dimensional views of a data set, PCA can be useful to understand ridge regression.</p>
<p>The <code>pca</code> method transforms a <code>"ridge"</code> object from parameter space, where the estimated coefficients are <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>Î²</mi><mi>k</mi></msub><annotation encoding="application/x-tex">\beta_k</annotation></semantics></math> with covariance matrices <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>Î£</mi><mi>k</mi></msub><annotation encoding="application/x-tex">\Sigma_k</annotation></semantics></math>, to the principal component space defined by the right singular vectors, <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>V</mi><annotation encoding="application/x-tex">V</annotation></semantics></math>, of the singular value decomposition of the scaled predictor matrix, <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>X</mi><annotation encoding="application/x-tex">X</annotation></semantics></math>.</p>
<div class="sourceCode" id="cb11"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">plridge</span> <span class="op">&lt;-</span> <span class="fu"><a href="reference/pca.html">pca</a></span><span class="op">(</span><span class="va">lridge</span><span class="op">)</span></span>
<span><span class="va">plridge</span></span>
<span><span class="co">#&gt; Ridge Coefficients:</span></span>
<span><span class="co">#&gt;        dim1     dim2     dim3     dim4     dim5     dim6   </span></span>
<span><span class="co">#&gt; 0.000  1.51541  0.37939  1.80131  0.34595  5.97391  6.74225</span></span>
<span><span class="co">#&gt; 0.005  1.51531  0.37928  1.79855  0.33886  5.32221  3.68519</span></span>
<span><span class="co">#&gt; 0.010  1.51521  0.37918  1.79579  0.33205  4.79871  2.53553</span></span>
<span><span class="co">#&gt; 0.020  1.51500  0.37898  1.79031  0.31922  4.00988  1.56135</span></span>
<span><span class="co">#&gt; 0.040  1.51459  0.37858  1.77944  0.29633  3.01774  0.88291</span></span>
<span><span class="co">#&gt; 0.080  1.51377  0.37778  1.75810  0.25915  2.01876  0.47238</span></span>
<span><span class="fu"><a href="reference/traceplot.html">traceplot</a></span><span class="op">(</span><span class="va">plridge</span><span class="op">)</span></span></code></pre></div>
<p><img src="reference/figures/README-pca-traceplot-1.png"><!-- --></p>
<p>What is perhaps surprising is that the coefficients for the first 4 components are not shrunk at all. Rather, the effect of shrinkage is seen only on the <em>last two dimensions</em>. These are the directions that contribute most to collinearity, for which other visualization methods have been proposed (Friendly &amp; Kwan 2009).</p>
<p>The <code><a href="https://rdrr.io/r/graphics/pairs.html" class="external-link">pairs()</a></code> plot illustrates the <em>joint</em> effects: the principal components of <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>ğ—</mi><annotation encoding="application/x-tex">\mathbf{X}</annotation></semantics></math> are uncorrelated, so the ellipses are all aligned with the coordinate axes and the ellipses largely coincide for dimensions 1 to 4:</p>
<div class="sourceCode" id="cb12"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/pairs.html" class="external-link">pairs</a></span><span class="op">(</span><span class="va">plridge</span><span class="op">)</span></span></code></pre></div>
<p><img src="reference/figures/README-pca-pairs-1.png" width="100%"></p>
<p>If we focus on the plot of dimensions <code>5:6</code>, we can see where all the shrinkage action is in this representation. Generally, the predictors that are related to the smallest dimension (6) are shrunk quickly at first.</p>
<div class="sourceCode" id="cb13"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">plridge</span>, variables<span class="op">=</span><span class="fl">5</span><span class="op">:</span><span class="fl">6</span>, fill <span class="op">=</span> <span class="cn">TRUE</span>, fill.alpha<span class="op">=</span><span class="fl">0.2</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/text.html" class="external-link">text</a></span><span class="op">(</span><span class="va">plridge</span><span class="op">$</span><span class="va">coef</span><span class="op">[</span>, <span class="fl">5</span><span class="op">:</span><span class="fl">6</span><span class="op">]</span>, </span>
<span>       label <span class="op">=</span> <span class="va">lambdaf</span>, </span>
<span>     cex<span class="op">=</span><span class="fl">1.5</span>, pos<span class="op">=</span><span class="fl">4</span>, offset<span class="op">=</span><span class="fl">.1</span><span class="op">)</span></span></code></pre></div>
<p><img src="reference/figures/README-pca-dim56-1.png"><!-- --></p>
<div class="section level3">
<h3 id="biplot-view">Biplot view<a class="anchor" aria-label="anchor" href="#biplot-view"></a>
</h3>
<p>Finally, we can project the <em>predictor variables</em> into the PCA space of the <em>smallest dimensions</em>, where the shrinkage action mostly occurs to see how the predictor variables relate to these dimensions.</p>
<p><code><a href="reference/biplot.pcaridge.html">biplot.pcaridge()</a></code> supplements the standard display of the covariance ellipsoids for a ridge regression problem in PCA/SVD space with labeled arrows showing the contributions of the original variables to the dimensions plotted. The length of the arrows reflects proportion of variance that each predictors shares with the components.</p>
<p>The biplot view showing the dimensions corresponding to the two smallest singular values is particularly useful for understanding how the predictors contribute to shrinkage in ridge regression. Here, <code>Year</code> and <code>Population</code> largely contribute to <code>dim 5</code>; a contrast between (<code>Year</code>, <code>Population</code>) and <code>GNP</code> contributes to <code>dim 6</code>.</p>
<div class="sourceCode" id="cb14"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">op</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/graphics/par.html" class="external-link">par</a></span><span class="op">(</span>mar<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">4</span>, <span class="fl">4</span>, <span class="fl">1</span>, <span class="fl">1</span><span class="op">)</span> <span class="op">+</span> <span class="fl">0.2</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/biplot.html" class="external-link">biplot</a></span><span class="op">(</span><span class="va">plridge</span>, radius<span class="op">=</span><span class="fl">0.5</span>, </span>
<span>       ref<span class="op">=</span><span class="cn">FALSE</span>, asp<span class="op">=</span><span class="fl">1</span>, </span>
<span>       var.cex<span class="op">=</span><span class="fl">1.15</span>, cex.lab<span class="op">=</span><span class="fl">1.3</span>, col<span class="op">=</span><span class="va">clr</span>,</span>
<span>       fill<span class="op">=</span><span class="cn">TRUE</span>, fill.alpha<span class="op">=</span><span class="fl">0.2</span>, prefix<span class="op">=</span><span class="st">"Dimension "</span><span class="op">)</span></span>
<span><span class="co">#&gt; Vector scale factor set to  5.247</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/text.html" class="external-link">text</a></span><span class="op">(</span><span class="va">plridge</span><span class="op">$</span><span class="va">coef</span><span class="op">[</span>,<span class="fl">5</span><span class="op">:</span><span class="fl">6</span><span class="op">]</span>, <span class="va">lambdaf</span>, pos<span class="op">=</span><span class="fl">2</span>, cex<span class="op">=</span><span class="fl">1.3</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/par.html" class="external-link">par</a></span><span class="op">(</span><span class="va">op</span><span class="op">)</span></span></code></pre></div>
<p><img src="reference/figures/README-fig.cap:%22Biplotviewoftheridgetraceplotforthesmallesttwodimensions,wheretheeffectsofshrinkagearemostapparent.%22-1.png"><!-- --></p>
</div>
</div>
<div class="section level2">
<h2 id="other-examples">Other examples<a class="anchor" aria-label="anchor" href="#other-examples"></a>
</h2>
<p>The genridge package contains four data sets, each with its own examples; e.g., you can try <code>example(Acetylene)</code>.</p>
<div class="sourceCode" id="cb15"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu">vcdExtra</span><span class="fu">::</span><span class="fu"><a href="http://friendly.github.io/vcdExtra/reference/datasets.html" class="external-link">datasets</a></span><span class="op">(</span>package<span class="op">=</span><span class="st">"genridge"</span><span class="op">)</span></span>
<span><span class="co">#&gt;        Item      class   dim                               Title</span></span>
<span><span class="co">#&gt; 1 Acetylene data.frame  16x4                      Acetylene Data</span></span>
<span><span class="co">#&gt; 2   Detroit data.frame 13x14 Detroit Homicide Data for 1961-1973</span></span>
<span><span class="co">#&gt; 3  Manpower data.frame  17x6              Hospital manpower data</span></span>
<span><span class="co">#&gt; 4  prostate data.frame 97x10                Prostate Cancer Data</span></span></code></pre></div>
</div>
<div class="section level2">
<h2 id="references">References<a class="anchor" aria-label="anchor" href="#references"></a>
</h2>
<p>Friendly, M. (2011). Generalized Ridge Trace Plots: Visualizing Bias <em>and</em> Precision with the <code>genridge</code> R package. SCS Seminar, Jan., 2011. Slides: <a href="http://euclid.psych.yorku.ca/datavis/papers/gentalk.pdf" class="external-link">gentalk.pdf</a>; <a href="http://euclid.psych.yorku.ca/datavis/papers/gentalk-2x2.pdf" class="external-link">gentalk-2x2.pdf</a></p>
<p>Friendly, M. (2013). The Generalized Ridge Trace Plot: Visualizing Bias <em>and</em> Precision. <em>Journal of Computational and Graphical Statistics</em>, <strong>22</strong>(1), 50-68, <a href="http://dx.doi.org/10.1080/10618600.2012.681237" class="external-link">DOI link</a>, Online: <a href="https://www.datavis.ca/papers/genridge-jcgs.pdf" class="external-link">genridge-jcgs.pdf</a>, Supp. materials: <a href="http://datavis.ca/papers/genridge-supp.zip" class="external-link">genridge-supp.zip</a></p>
<p>Friendly, M., and Kwan, E. (2009), Whereâ€™s Waldo: Visualizing Collinearity Diagnostics, <em>The American Statistician</em>, <strong>63</strong>(1), 56â€“65, <a href="https://doi.org/10.1198/tast.2009.0012" class="external-link">DOI link</a>, Online: <a href="http://datavis.ca/papers/viscollin-tast.pdf" class="external-link">viscollin-tast.pdf</a>, Supp. materials: <a href="http://datavis.ca/papers/viscollin/" class="external-link uri">http://datavis.ca/papers/viscollin/</a>.</p>
<p>Friendly, M., Monette, G., &amp; Fox, J. (2013). Elliptical Insights: Understanding Statistical Methods Through Elliptical Geometry. <em>Statistical Science</em>, <strong>28</strong>(1), 1â€“39. <a href="https://doi.org/10.1214/12-STS402" class="external-link uri">https://doi.org/10.1214/12-STS402</a></p>
<p>Hoerl, A. E., Kennard, R. W., and Baldwin, K. F. (1975), Ridge Regression: Some Simulations, <em>Communications in Statistics</em>, <strong>4</strong>, 105â€“123.</p>
<p>Lawless, J. F., and Wang, P. (1976), A Simulation Study of Ridge and Other Regression Estimators, <em>Communications in Statistics</em>, <strong>5</strong>, 307â€“323.</p>
<p>Longley, J. W. (1967) An appraisal of least-squares programs from the point of view of the user. <em>Journal of the American Statistical Association</em>, <strong>62</strong>, 819â€“841.</p>
</div>
</div>

  </main><aside class="col-md-3"><div class="links">
<h2 data-toc-skip>Links</h2>
<ul class="list-unstyled">
<li><a href="https://cloud.r-project.org/package=genridge" class="external-link">View on CRAN</a></li>
<li><a href="https://github.com/friendly/genridge/" class="external-link">Browse source code</a></li>
<li><a href="https://github.com/friendly/genridge/issues" class="external-link">Report a bug</a></li>
</ul>
</div>

<div class="license">
<h2 data-toc-skip>License</h2>
<ul class="list-unstyled">
<li>GPL (&gt;= 2)</li>
</ul>
</div>


<div class="citation">
<h2 data-toc-skip>Citation</h2>
<ul class="list-unstyled">
<li><a href="authors.html#citation">Citing genridge</a></li>
</ul>
</div>

<div class="developers">
<h2 data-toc-skip>Developers</h2>
<ul class="list-unstyled">
<li>Michael Friendly <br><small class="roles"> Author, maintainer </small> <a href="https://orcid.org/0000-0002-3237-0941" target="orcid.widget" aria-label="ORCID" class="external-link"><span class="fab fa-orcid orcid" aria-hidden="true"></span></a> </li>
</ul>
</div>

<div class="dev-status">
<h2 data-toc-skip>Dev status</h2>
<ul class="list-unstyled">
<li><a href="https://zenodo.org/badge/latestdoi/105555707" class="external-link"><img src="https://zenodo.org/badge/105555707.svg" alt="DOI"></a></li>
<li><a href="https://cran.r-project.org/package=genridge" class="external-link"><img src="http://www.r-pkg.org/badges/version/genridge" alt="CRAN_Status_Badge"></a></li>
<li><a href="https://friendly.r-universe.dev" class="external-link"><img src="https://friendly.r-universe.dev/badges/genridge" alt="R-universe"></a></li>
<li><a href="https://cran.r-project.org/package=genridge" class="external-link"><img src="http://cranlogs.r-pkg.org/badges/grand-total/genridge" alt="downloads"></a></li>
<li><a href="https://friendly.github.io/genridge"><img src="https://img.shields.io/badge/pkgdown%20site-blue" alt="pkgdown"></a></li>
</ul>
</div>

  </aside>
</div>


    <footer><div class="pkgdown-footer-left">
  <p>Developed by Michael Friendly.</p>
</div>

<div class="pkgdown-footer-right">
  <p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.1.1.</p>
</div>

    </footer>
</div>





  </body>
</html>
